{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow configuration.\n",
    "\n",
    "Without setting memory growth TF 2 runs into problems, see [this issue](https://github.com/tensorflow/tensorflow/issues/24496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "float_dtype = 'float16'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from deeplearning_image_classification import data_loading\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "np.random.seed(0)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "DATA_DIR = data_loading.DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "if float_dtype == 'float16': \n",
    "    tf.keras.backend.set_floatx('float16')\n",
    "    tf.keras.backend.set_epsilon(1e-4)\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "train_csv_path = os.path.join(DATA_DIR, 'train_metadata.csv')\n",
    "test_csv_path = os.path.join(DATA_DIR, 'test_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_metadata(train_metadata_path=train_csv_path, test_metadata_path=test_csv_path):\n",
    "    train_metadata_df = pd.read_csv(train_csv_path)\n",
    "    test_metadata_df = pd.read_csv(test_csv_path)\n",
    "    return train_metadata_df, test_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df, test_metadata_df = get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 11000\n",
    "sample_val_size = 1000\n",
    "__, sample_train_val_metadata_df = model_selection.train_test_split(train_metadata_df, test_size=sample_size, random_state=2, stratify=train_metadata_df['class'])\n",
    "sample_train_metadata_df, sample_val_metadata_df = model_selection.train_test_split(sample_train_val_metadata_df, test_size=sample_val_size, random_state=2, stratify=sample_train_val_metadata_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_size = (224, 224)\n",
    "train_batch_size = 48 \n",
    "val_batch_size = 48\n",
    "test_batch_size = 48\n",
    "\n",
    "\n",
    "def get_train_val_test_iterators(train_metadata_df, val_metadata_df, test_metadata_df, image_size, train_batch_size, val_batch_size, test_batch_size):\n",
    "    image_gen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_image_iterator = image_gen.flow_from_dataframe(train_metadata_df, batch_size=train_batch_size, target_size=image_size,\n",
    "        shuffle=True)\n",
    "    val_image_iterator = image_gen.flow_from_dataframe(val_metadata_df, batch_size=val_batch_size, target_size=image_size, shuffle=False)\n",
    "    test_image_iterator = image_gen.flow_from_dataframe(test_metadata_df, batch_size=test_batch_size, target_size=image_size, shuffle=False)\n",
    "    return train_image_iterator, val_image_iterator, test_image_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_iterator, val_image_iterator, test_image_iterator = get_train_val_test_iterators(sample_train_metadata_df, sample_val_metadata_df, test_metadata_df, image_size=image_size, train_batch_size=train_batch_size, test_batch_size=test_batch_size, val_batch_size=val_batch_size) \n",
    "n_classes = len(train_image_iterator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up model\n",
    "\n",
    "We use pretrained MobileNet model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "learning_rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "default_metrics = [\n",
    "    'acc',\n",
    "   keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "   keras.metrics.Precision(),\n",
    "   keras.metrics.Recall()\n",
    "]\n",
    "pretrained = False\n",
    "freeze_pretrained = False\n",
    "last_layer_convolutions = 64\n",
    "\n",
    "\n",
    "def setup_model(n_classes, optimizer, metrics):\n",
    "    weights =  'imagenet' if pretrained else None\n",
    "    base_model = keras_applications.mobilenet.MobileNet(weights=None, input_shape=(*image_size, 3), backend=tf.keras.backend, layers=tf.keras.layers, models=tf.keras.models, utils=tf.keras.utils) \n",
    "    if freeze_pretrained:\n",
    "        base_model.trainable = False\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            base_model,\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(n_classes, dtype=float_dtype),\n",
    "            keras.layers.Softmax()\n",
    "        ])\n",
    "    model.compile(\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = setup_model(n_classes, optimizer, default_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_image_iterator, validation_data=val_image_iterator, epochs=10, use_multiprocessing=True, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_image_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_image_iterator).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([test_image_iterator.class_indices[c] for c in test_metadata_df['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "sample_size = 11000\n",
    "val_size = 1000\n",
    "epochs = 20 \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_val_metadata_df, test_metadata_df = get_metadata()\n",
    "    \n",
    "    if sample_size != 'all':\n",
    "        __, train_val_metadata_df = model_selection.train_test_split(\n",
    "            train_val_metadata_df,\n",
    "            test_size=sample_size,\n",
    "            random_state=2,\n",
    "            stratify=train_val_metadata_df['class']\n",
    "        )\n",
    "    train_metadata_df, val_metadata_df = model_selection.train_test_split(\n",
    "        train_val_metadata_df,\n",
    "        test_size=val_size,\n",
    "        random_state=2,\n",
    "        stratify=train_val_metadata_df['class']\n",
    "    )\n",
    "        \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        monitor='val_top_k_categorical_accuracy'\n",
    "    )\n",
    "    tensorboard_training_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,\n",
    "        update_freq=100, profile_batch=2, embeddings_freq=0,\n",
    "        embeddings_metadata=None\n",
    "    )\n",
    "    tensorboard_epoch_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,\n",
    "        update_freq='epoch', profile_batch=2, embeddings_freq=0,\n",
    "        embeddings_metadata=None\n",
    "    )\n",
    "    callbacks = [model_checkpoint_callback, tensorboard_training_callback, tensorboard_epoch_callback]\n",
    "    train_image_iterator, val_image_iterator, test_image_iterator = get_train_val_test_iterators(\n",
    "        train_metadata_df, val_metadata_df, test_metadata_df,\n",
    "        image_size=image_size, train_batch_size=train_batch_size, test_batch_size=test_batch_size, val_batch_size=val_batch_size) \n",
    "    n_classes = len(train_image_iterator.class_indices)\n",
    "    model = setup_model(n_classes, optimizer, default_metrics)\n",
    "    model.fit(train_image_iterator, validation_data=val_image_iterator, epochs=epochs, callbacks=callbacks)\n",
    "    model.save('data/model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
